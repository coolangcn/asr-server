#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, argparse, tempfile, subprocess
import numpy as np
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
import torch

# å’Œ asr_server.py ä¿æŒä¸€è‡´
SPEAKER_DB_FILE = "speaker_db_multi.json"

SV_MODELS = {
    "eres2net_large": {
        "id": "iic/speech_eres2net_large_200k_sv_zh-cn_16k-common",
        "rev": "v1.0.0",
    },
    "rdino_ecapa": {
        "id": "iic/speech_rdino_ecapa_tdnn_sv_zh-cn_cnceleb_16k",
        "rev": "v1.0.0",
    }
}

def preprocess_audio(input_path, output_path):
    cmd = [
        "ffmpeg", "-v", "error", "-y",
        "-i", input_path,
        "-ac", "1", "-ar", "16000",
        output_path
    ]
    try:
        subprocess.run(cmd, check=True)
        return True
    except:
        return False

def extract_embedding(sv_pipe, wav_path):
    """ä½¿ç”¨åº•å±‚æ¨¡å‹æå– embeddingï¼ˆé¿å…ä¸¤è¾“å…¥æŠ¥é”™ï¼‰"""
    try:
        model = sv_pipe.model

        import torchaudio
        audio, sr = torchaudio.load(wav_path)

        if sr != 16000:
            resample = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
            audio = resample(audio)

        # [C, T] -> [1, T]
        audio = audio.mean(dim=0, keepdim=True)

        # ä¸è¦ unsqueezeï¼Œä¸è¦å˜æˆ [1,1,T]
        # æ¨¡å‹è¦æ±‚ [1, T]

        with torch.no_grad():
            out = model(audio)
            if isinstance(out, dict):
                emb = out.get("spk_embedding")
            else:
                emb = out

        return emb.squeeze().cpu().numpy().tolist()

    except Exception as e:
        print("âŒ Extract embedding failed:", e)
        return None


def register_speaker(name, audio_file):
    print(f"ğŸ“¥ å¤„ç†éŸ³é¢‘: {audio_file}")

    # 1. é¢„å¤„ç†
    tmp = os.path.join(tempfile.gettempdir(), f"reg_{os.path.basename(audio_file)}")
    if not preprocess_audio(audio_file, tmp):
        print("âŒ FFmpeg è½¬æ¢å¤±è´¥")
        return

    # 2. åŠ è½½æ•°æ®åº“
    if os.path.exists(SPEAKER_DB_FILE):
        with open(SPEAKER_DB_FILE, "r", encoding="utf-8") as f:
            db = json.load(f)
    else:
        db = {}

    if name not in db:
        db[name] = {}

    # 3. éå†æ‰€æœ‰æ¨¡å‹æå– embedding
    for model_name, conf in SV_MODELS.items():
        print(f"  ğŸ” ä½¿ç”¨æ¨¡å‹ {model_name} æå– embedding ...")

        sv = pipeline(
            task=Tasks.speaker_verification,
            model=conf["id"],
            model_revision=conf["rev"],
            device="cuda"
        )

        emb = extract_embedding(sv, tmp)
        if emb is None:
            print(f"  âŒ {model_name} æå–å¤±è´¥")
            continue

        db[name][model_name] = emb
        print(f"  âœ… {model_name} æå–æˆåŠŸ, ç»´åº¦: {len(emb)}")

    # 4. ä¿å­˜
    with open(SPEAKER_DB_FILE, "w", encoding="utf-8") as f:
        json.dump(db, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ‰ å£°çº¹æ³¨å†Œå®Œæˆ: {name}")
    print(f"ğŸ“¦ å·²ä¿å­˜åˆ°: {SPEAKER_DB_FILE}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--name", required=True, help="è¯´è¯äººåç§°")
    parser.add_argument("--audio", required=True, help="å•æ®µéŸ³é¢‘ï¼ˆ3-10 ç§’ï¼‰")
    args = parser.parse_args()

    register_speaker(args.name, args.audio)
