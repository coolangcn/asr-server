#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""æ·»åŠ Whisperé…ç½®å’ŒåŠŸèƒ½"""

with open('asr_server.py', 'r', encoding='utf-8') as f:
    content = f.read()

# 1. æ·»åŠ Whisperé…ç½®
old_config = """    # æƒ…æ„Ÿæ£€æµ‹é…ç½®
    EMOTION_MODEL = "iic/SenseVoiceSmall"
    ENABLE_EMOTION_DETECTION = True  # æ˜¯å¦å¯ç”¨æƒ…æ„Ÿæ£€æµ‹"""

new_config = """    # æƒ…æ„Ÿæ£€æµ‹é…ç½®
    EMOTION_MODEL = "iic/SenseVoiceSmall"
    ENABLE_EMOTION_DETECTION = True  # æ˜¯å¦å¯ç”¨æƒ…æ„Ÿæ£€æµ‹
    
    # Whisperå¯¹æ¯”é…ç½®
    WHISPER_MODEL = "small"  # tiny/base/small/medium/large-v3
    ENABLE_WHISPER_COMPARISON = True  # æ˜¯å¦å¯ç”¨Whisperå¯¹æ¯”è¯†åˆ«"""

content = content.replace(old_config, new_config)

# 2. æ·»åŠ whisperå¯¼å…¥
old_import = "from db_manager import save_to_db\nfrom logging.handlers import TimedRotatingFileHandler"
new_import = "from db_manager import save_to_db\nfrom logging.handlers import TimedRotatingFileHandler\nimport whisper"

content = content.replace(old_import, new_import)

# 3. æ·»åŠ whisper_modelå…¨å±€å˜é‡
old_globals = "emotion_pipeline = None  # æƒ…æ„Ÿæ£€æµ‹æ¨¡å‹"
new_globals = "emotion_pipeline = None  # æƒ…æ„Ÿæ£€æµ‹æ¨¡å‹\nwhisper_model = None  # Whisperå¯¹æ¯”æ¨¡å‹"

content = content.replace(old_globals, new_globals)

# 4. åœ¨load_models()ä¸­æ·»åŠ WhisperåŠ è½½
old_load = """    else:
        print("â­ï¸  è·³è¿‡æƒ…æ„Ÿæ£€æµ‹æ¨¡å‹åŠ è½½ï¼ˆå·²ç¦ç”¨ï¼‰")

    # 4. åŠ è½½ SV æ¨¡å‹"""

new_load = """    else:
        print("â­ï¸  è·³è¿‡æƒ…æ„Ÿæ£€æµ‹æ¨¡å‹åŠ è½½ï¼ˆå·²ç¦ç”¨ï¼‰")

    # 4. åŠ è½½Whisperå¯¹æ¯”æ¨¡å‹
    global whisper_model
    if Config.ENABLE_WHISPER_COMPARISON:
        print(f"ğŸ¤ åŠ è½½Whisperå¯¹æ¯”æ¨¡å‹: {Config.WHISPER_MODEL} ...")
        whisper_model = whisper.load_model(Config.WHISPER_MODEL, device=Config.DEVICE.split(':')[0])
        print("âœ… Whisperå¯¹æ¯”æ¨¡å‹åŠ è½½å®Œæˆ")
    else:
        print("â­ï¸  è·³è¿‡Whisperå¯¹æ¯”æ¨¡å‹åŠ è½½ï¼ˆå·²ç¦ç”¨ï¼‰")

    # 5. åŠ è½½ SV æ¨¡å‹"""

content = content.replace(old_load, new_load)

# 5. æ·»åŠ Whisperè¯†åˆ«å‡½æ•°ï¼ˆåœ¨detect_emotion_for_segmentä¹‹åï¼‰
whisper_function = '''

def transcribe_with_whisper(audio_path):
    """
    ä½¿ç”¨Whisperè¯†åˆ«éŸ³é¢‘ç‰‡æ®µï¼ˆä½œä¸ºFunASRçš„å¯¹æ¯”å‚è€ƒï¼‰
    
    Args:
        audio_path: éŸ³é¢‘ç‰‡æ®µè·¯å¾„
        
    Returns:
        str: Whisperè¯†åˆ«çš„æ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    if not Config.ENABLE_WHISPER_COMPARISON or whisper_model is None:
        return None
    
    try:
        result = whisper_model.transcribe(
            audio_path,
            language='zh',
            fp16=True,  # GPUåŠ é€Ÿ
            verbose=False
        )
        whisper_text = result['text'].strip()
        logger.info(f"      [Whisperå¯¹æ¯”] {whisper_text}")
        return whisper_text
    except Exception as e:
        logger.warning(f"      [Whisperå¯¹æ¯”] è¯†åˆ«å¤±è´¥: {e}")
        return None
'''

# æ‰¾åˆ°detect_emotion_for_segmentå‡½æ•°ç»“æŸçš„ä½ç½®
detect_end = content.find("# =================== æå– embedding")
if detect_end > 0:
    content = content[:detect_end] + whisper_function + "\n" + content[detect_end:]

with open('asr_server.py', 'w', encoding='utf-8') as f:
    f.write(content)

print("âœ… æˆåŠŸæ·»åŠ Whisperé…ç½®å’ŒåŠŸèƒ½!")
print("  - æ·»åŠ äº†WHISPER_MODELå’ŒENABLE_WHISPER_COMPARISONé…ç½®")
print("  - æ·»åŠ äº†whisper_modelå…¨å±€å˜é‡")
print("  - åœ¨load_models()ä¸­åŠ è½½Whisperæ¨¡å‹")
print("  - åˆ›å»ºäº†transcribe_with_whisper()å‡½æ•°")
